{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "747d5f33-b0eb-4358-a992-e72c0055f0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "def read_and_clean_vilistus_csv(file_path, keep_time=False):\n",
    "    # Auto-generate output Excel path\n",
    "    base_name = os.path.splitext(file_path)[0]\n",
    "    output_excel_path = base_name + \".xlsx\"\n",
    "\n",
    "    # Read file\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Separate headers and data\n",
    "    header_lines = []\n",
    "    data_lines = []\n",
    "    data_start = False\n",
    "\n",
    "    for line in lines:\n",
    "        if re.match(r\"\\d{2}:\\d{2}:\\d{2}:\\d{3}\", line):\n",
    "            data_start = True\n",
    "        if not data_start:\n",
    "            header_lines.append(line.strip())\n",
    "        else:\n",
    "            data_lines.append(line.strip())\n",
    "\n",
    "    # Extract headers\n",
    "    headers = []\n",
    "    for line in header_lines:\n",
    "        match = re.match(r\"Column #\\d+\\s*:\\s*Sensor \\d+\\s*:\\s*(.*?)\\s+\\*\\*\\*\", line)\n",
    "        if match:\n",
    "            headers.append(match.group(1).strip())\n",
    "\n",
    "    if not headers:\n",
    "        raise ValueError(\"No valid headers found.\")\n",
    "\n",
    "    # Parse data\n",
    "    data = []\n",
    "    timestamps = []\n",
    "    for line in data_lines:\n",
    "        parts = [p.strip() for p in line.split(',')]\n",
    "        if len(parts) < len(headers) + 1:\n",
    "            continue  # skip bad rows\n",
    "        try:\n",
    "            if keep_time:\n",
    "                timestamps.append(parts[0])\n",
    "            values = [float(x) for x in parts[1:]]\n",
    "            data.append(values)\n",
    "        except ValueError:\n",
    "            continue  # skip malformed floats\n",
    "\n",
    "    # Build DataFrame\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    if keep_time:\n",
    "        df.insert(0, \"Timestamp\", timestamps)\n",
    "\n",
    "    # Save to Excel\n",
    "    df.to_excel(output_excel_path, index=False)\n",
    "    print(f\"Cleaned data saved to: {output_excel_path}\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2b54a2b-99c0-410d-b9b5-027863475e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to: 20015.xlsx\n",
      "Cleaned data saved to: NA491.xlsx\n",
      "Cleaned data saved to: MA301.xlsx\n",
      "Cleaned data saved to: SA039.xlsx\n",
      "Cleaned data saved to: RU745.xlsx\n",
      "Cleaned data saved to: IN824.xlsx\n",
      "Cleaned data saved to: AR833.xlsx\n",
      "Cleaned data saved to: Ro590.xlsx\n",
      "Cleaned data saved to: SA997.xlsx\n",
      "Cleaned data saved to: MA662.xlsx\n",
      "Cleaned data saved to: SA974.xlsx\n",
      "Cleaned data saved to: MA598.xlsx\n",
      "Cleaned data saved to: AB191.xlsx\n",
      "Cleaned data saved to: UG111.xlsx\n",
      "Cleaned data saved to: RO807.xlsx\n",
      "Cleaned data saved to: PE472.xlsx\n",
      "Cleaned data saved to: SU786.xlsx\n",
      "Cleaned data saved to: VE008.xlsx\n",
      "Cleaned data saved to: VI207.xlsx\n",
      "Cleaned data saved to: RA147.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Loop through all CSV files in the current directory\n",
    "for file in os.listdir('.'):\n",
    "    if file.lower().endswith('.csv'):\n",
    "        read_and_clean_vilistus_csv(file, keep_time=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a94bc524-53b6-4472-b6bd-1bb5d2bd1bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to: 20015.xlsx\n"
     ]
    }
   ],
   "source": [
    "df=read_and_clean_vilistus_csv(\"20015.csv\", keep_time=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6757f61-2941-4da6-a442-4c42a760ac12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.501928313364266)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Alpha Amp.\"].abs().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3bb238-2119-4258-8396-e588b879d032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
